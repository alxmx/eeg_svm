#!/usr/bin/env python3
"""
Analysis script for EEG/EDA scaling issues based on session logs
"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

def analyze_session_data(session_file, baseline_file, stats_file):
    """Analyze session data to understand scaling issues"""
    
    print("="*60)
    print("EEG/EDA SCALING ANALYSIS REPORT")
    print("="*60)
    
    # Load data
    session_df = pd.read_csv(session_file)
    baseline_df = pd.read_csv(baseline_file) 
    stats_df = pd.read_csv(stats_file)
    
    feature_names = ['theta_fz', 'alpha_po', 'faa', 'beta_frontal', 'eda_norm']
    
    print(f"\n1. SESSION OVERVIEW:")
    print(f"   - Session file: {session_file}")
    print(f"   - Baseline file: {baseline_file}")
    print(f"   - Session duration: {len(session_df)} seconds")
    
    print(f"\n2. MI ANALYSIS:")
    mi_stats = session_df['mi'].describe()
    print(f"   - MI range: {mi_stats['min']:.6f} to {mi_stats['max']:.6f}")
    print(f"   - MI std: {mi_stats['std']:.2e}")
    if mi_stats['std'] < 1e-10:
        print("   ‚ùå CRITICAL: MI values are essentially constant - MODEL SATURATED!")
    else:
        print("   ‚úÖ MI values show variation")
    
    print(f"\n3. FEATURE SCALING COMPARISON:")
    print(f"   {'Feature':<15} {'Baseline Range':<20} {'Session Range':<20} {'Scale Diff':<15} Status")
    print("-" * 85)
    
    scaling_issues = []
    for feat in feature_names:
        if feat in baseline_df.columns and feat in session_df.columns:
            # Baseline stats
            baseline_min = baseline_df[feat].min()
            baseline_max = baseline_df[feat].max()
            baseline_range = baseline_max - baseline_min
            
            # Session stats  
            session_min = session_df[feat].min()
            session_max = session_df[feat].max()
            session_range = session_max - session_min
            
            # Calculate scale difference
            if baseline_range > 0 and session_range > 0:
                scale_ratio = session_range / baseline_range
                scale_diff = abs(np.log10(scale_ratio))
            else:
                scale_ratio = 0
                scale_diff = float('inf')
            
            # Status determination
            if scale_diff > 3:  # More than 1000x difference
                status = "‚ùå CRITICAL"
                scaling_issues.append((feat, scale_ratio, "Critical scaling mismatch"))
            elif scale_diff > 1:  # More than 10x difference
                status = "‚ö†Ô∏è  WARNING"
                scaling_issues.append((feat, scale_ratio, "Significant scaling difference"))
            else:
                status = "‚úÖ OK"
            
            baseline_str = f"{baseline_min:.2e}-{baseline_max:.2e}"
            session_str = f"{session_min:.2e}-{session_max:.2e}"
            scale_str = f"{scale_ratio:.2e}" if scale_ratio != 0 else "N/A"
            
            print(f"   {feat:<15} {baseline_str:<20} {session_str:<20} {scale_str:<15} {status}")
    
    print(f"\n4. SCALING ISSUES IDENTIFIED:")
    if scaling_issues:
        for feat, ratio, issue in scaling_issues:
            print(f"   - {feat}: {issue} (ratio: {ratio:.2e})")
            
            # Specific recommendations
            if feat.startswith(('theta', 'alpha', 'beta')) and ratio < 0.001:
                print(f"     RECOMMENDATION: Remove EEG scaling factor - values are 1000x too small")
            elif feat == 'eda_norm' and ratio > 1000:
                print(f"     RECOMMENDATION: Apply EDA scaling factor - values are 1000x too large")
    else:
        print("   ‚úÖ No major scaling issues detected")
    
    print(f"\n5. MODEL PERFORMANCE INDICATORS:")
    # Check for model saturation
    unique_mi = len(session_df['mi'].unique())
    if unique_mi < 5:
        print(f"   ‚ùå Model saturation: Only {unique_mi} unique MI values")
        print("   CAUSE: Extreme feature scaling causing model to saturate")
    else:
        print(f"   ‚úÖ Model variation: {unique_mi} unique MI values")
    
    # Check R¬≤ from calibration
    print(f"\n6. RECOMMENDED FIXES:")
    if any("Critical" in issue[2] for issue in scaling_issues):
        print("   1. Set eeg_scale_factor = 1.0 (remove aggressive 0.001 scaling)")
        print("   2. Set eda_scale_factor = 1.0 (unless EDA values are extreme)")
        print("   3. Ensure calibration and real-time use identical scaling")
        print("   4. Re-calibrate user after fixing scaling")
    else:
        print("   ‚úÖ Current scaling appears appropriate")
    
    return scaling_issues

def main():
    # Analyze the user 007_alex_test session - CRITICAL ISSUES DETECTED
    session_file = "logs/007_alex_test_mi_session_20250625_200204.csv"
    baseline_file = "user_configs/007_alex_test_baseline.csv" 
    stats_file = "logs/007_alex_test_mi_feature_stats_20250625_200204.csv"
    
    if all(Path(f).exists() for f in [session_file, baseline_file, stats_file]):
        scaling_issues = analyze_session_data(session_file, baseline_file, stats_file)
        
        print(f"\n" + "="*60)
        print("SUMMARY CONCLUSION:")
        print("="*60)
        
        if scaling_issues:
            print("‚ùå SCALING ISSUES DETECTED - Model performance compromised")
            print("‚úÖ FIXED: Updated realtime_mi_lsl.py with corrected scaling factors")
            print("üìã NEXT STEPS:")
            print("   1. Run calibration again with fixed scaling")
            print("   2. Test real-time session to verify MI variation")
            print("   3. Check that MI values vary meaningfully (not constant)")
        else:
            print("‚úÖ No critical scaling issues found")
            
    else:
        print("Error: Required files not found. Please ensure session data exists.")
        print(f"Looking for:")
        for f in [session_file, baseline_file, stats_file]:
            exists = "‚úÖ" if Path(f).exists() else "‚ùå"
            print(f"  {exists} {f}")

def analyze_007_alex_test():
    """Specific analysis for user 007_alex_test with critical MI saturation"""
    
    print("="*80)
    print("CRITICAL ANALYSIS: USER 007_alex_test - MI COMPLETELY SATURATED")
    print("="*80)
    
    # Load data
    session_file = "logs/007_alex_test_mi_session_20250625_200204.csv"
    baseline_file = "user_configs/007_alex_test_baseline.csv"
    stats_file = "logs/007_alex_test_mi_feature_stats_20250625_200204.csv"
    
    session_df = pd.read_csv(session_file)
    baseline_df = pd.read_csv(baseline_file)
    
    print(f"\nüö® CRITICAL ISSUE DETECTED:")
    print(f"   - MI values are COMPLETELY CONSTANT: {session_df['mi'].iloc[0]:.15f}")
    print(f"   - MI std deviation: {session_df['mi'].std():.2e} (essentially zero)")
    print(f"   - This indicates COMPLETE MODEL SATURATION")
    
    print(f"\nüìä EDA SCALING ANALYSIS:")
    # Check EDA values - this is likely the main issue
    baseline_eda_mean = baseline_df['eda_norm'].mean()
    baseline_eda_std = baseline_df['eda_norm'].std()
    session_eda_mean = session_df['eda_norm'].mean()
    session_eda_std = session_df['eda_norm'].std()
    
    print(f"   Baseline EDA: Mean={baseline_eda_mean:.6f}, Std={baseline_eda_std:.6f}")
    print(f"   Session EDA:  Mean={session_eda_mean:.6f}, Std={session_eda_std:.6f}")
    print(f"   EDA Scale Ratio: {session_eda_mean / baseline_eda_mean:.1f}x")
    
    if session_eda_mean / baseline_eda_mean > 100:
        print("   ‚ùå CRITICAL: EDA values are ~600x larger in session vs baseline!")
        print("   üîß CAUSE: EDA scaling factor needs to be applied during real-time")
        
    print(f"\nüìä EEG SCALING ANALYSIS:")
    eeg_features = ['theta_fz', 'alpha_po', 'faa', 'beta_frontal']
    for feat in eeg_features:
        baseline_mean = baseline_df[feat].mean()
        session_mean = session_df[feat].mean()
        ratio = session_mean / baseline_mean if baseline_mean != 0 else float('inf')
        print(f"   {feat}: Baseline={baseline_mean:.3f}, Session={session_mean:.3f}, Ratio={ratio:.3f}")
    
    print(f"\nüîß ROOT CAUSE ANALYSIS:")
    print("   1. EDA values in baseline: ~0.01-0.09 range")
    print("   2. EDA values in session: ~6-9 range") 
    print("   3. This is a ~600x difference causing extreme feature scaling")
    print("   4. SVR model trained on small EDA values, gets huge EDA in real-time")
    print("   5. Model saturates and outputs constant MI value")
    
    print(f"\n‚úÖ SOLUTION:")
    print("   1. Apply EDA scaling factor during real-time: eda_value * 0.001")
    print("   2. OR re-calibrate with consistent EDA scaling")
    print("   3. Ensure EDA normalization is applied consistently")
    print("   4. Check EDA channel selection (may be using wrong channel)")
    
    print(f"\nüìã RECOMMENDED ACTIONS:")
    print("   1. Check realtime_mi_lsl.py EDA scaling logic")
    print("   2. Verify EDA channel index configuration")
    print("   3. Apply robust EDA normalization during real-time")
    print("   4. Re-calibrate user with fixed EDA scaling")
    print("   5. Test that MI varies after fix")

def analyze_008_alex_test():
    """Specific analysis for user 008_alex_test"""
    print("="*80)
    print("ANALYSIS: USER 008_alex_test")
    print("="*80)

    # Load data
    session_file = "logs/008_alex_test_mi_session_20250625_202532.csv"
    baseline_file = "user_configs/008_alex_test_baseline.csv"
    stats_file = "logs/008_alex_test_mi_feature_stats_20250625_202532.csv"

    if Path(session_file).exists():
        session_df = pd.read_csv(session_file)
        print(f"\nSESSION FILE LOADED: {session_file}")
        print(f"Session Duration: {len(session_df)} seconds")

        # Analyze MI values
        mi_stats = session_df['mi'].describe()
        print(f"\nMI ANALYSIS:")
        print(f"   - MI range: {mi_stats['min']:.6f} to {mi_stats['max']:.6f}")
        print(f"   - MI std: {mi_stats['std']:.2e}")
        if mi_stats['std'] < 1e-10:
            print("   ‚ùå CRITICAL: MI values are essentially constant - MODEL SATURATED!")
        else:
            print("   ‚úÖ MI values show variation")

        # Analyze features
        feature_names = ['theta_fz', 'alpha_po', 'faa', 'beta_frontal', 'eda_norm']
        print(f"\nFEATURE ANALYSIS:")
        for feat in feature_names:
            if feat in session_df.columns:
                feat_stats = session_df[feat].describe()
                print(f"   {feat}: min={feat_stats['min']:.6f}, max={feat_stats['max']:.6f}, mean={feat_stats['mean']:.6f}")

        print("\nANALYSIS COMPLETED FOR USER 008_alex_test")
    else:
        print(f"‚ùå SESSION FILE NOT FOUND: {session_file}")

if __name__ == "__main__":
    # Run specific analysis for 007_alex_test
    analyze_007_alex_test()
    print("\n" + "="*80)
    print("Running general analysis...")
    print("="*80)
    main()
    print("\n" + "="*80)
    print("Running analysis for user 008_alex_test...")
    print("="*80)
    analyze_008_alex_test()
